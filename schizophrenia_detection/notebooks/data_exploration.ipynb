{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook for Schizophrenia Detection\n",
    "\n",
    "This notebook is optimized for Google Colab and provides tools for exploring fMRI and MEG data for schizophrenia detection.\n",
    "\n",
    "## Features:\n",
    "- GPU configuration and memory management\n",
    "- Google Drive integration for data storage\n",
    "- Interactive visualizations\n",
    "- Data quality checks and validation\n",
    "- Progress tracking for long operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for data storage and model checkpoints\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    import os\n",
    "    \n",
    "    # Check if already mounted\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        print(\"Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "    else:\n",
    "        print(\"Google Drive already mounted\")\n",
    "    \n",
    "    # Set up project directory\n",
    "    project_path = '/content/drive/MyDrive/schizophrenia_detection'\n",
    "    os.makedirs(project_path, exist_ok=True)\n",
    "    print(f\"Project directory: {project_path}\")\n",
    "else:\n",
    "    import os\n",
    "    project_path = os.path.abspath('../')\n",
    "    print(f\"Local project directory: {project_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages specific to Colab environment\n",
    "if IN_COLAB:\n",
    "    print(\"Installing required packages...\")\n",
    "    \n",
    "    # Core packages\n",
    "    !pip install nibabel nilearn mne scikit-learn matplotlib seaborn tqdm -q\n",
    "    \n",
    "    # Interactive visualization packages\n",
    "    !pip install plotly ipywidgets -q\n",
    "    \n",
    "    # Memory management packages\n",
    "    !pip install psutil -q\n",
    "    \n",
    "    # Advanced neuroimaging packages\n",
    "    !pip install dipy pydicom -q\n",
    "    \n",
    "    print(\"Packages installed successfully!\")\n",
    "else:\n",
    "    print(\"Skipping package installation in local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GPU Configuration and Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and configure memory\n",
    "if IN_COLAB:\n",
    "    import tensorflow as tf\n",
    "    from psutil import virtual_memory\n",
    "    \n",
    "    # Check GPU availability\n",
    "    gpu_available = tf.test.is_gpu_available()\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"GPU available: {gpu_available}\")\n",
    "    \n",
    "    if gpu_available:\n",
    "        gpu_name = tf.test.gpu_device_name()\n",
    "        print(f\"GPU device: {gpu_name}\")\n",
    "        \n",
    "        # Configure GPU memory growth to prevent OOM errors\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                for gpu in gpus:\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                print(\"GPU memory growth enabled\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error setting GPU memory growth: {e}\")\n",
    "    \n",
    "    # Check RAM availability\n",
    "    ram_gb = virtual_memory().total / 1e9\n",
    "    print(f\"Available RAM: {ram_gb:.2f} GB\")\n",
    "    \n",
    "    if ram_gb < 12:\n",
    "        print(\"WARNING: Low RAM detected. Consider reducing batch sizes and data loading.\")\n",
    "else:\n",
    "    print(\"Skipping GPU configuration in local environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory management utilities\n",
    "import gc\n",
    "import psutil\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def check_memory_usage():\n",
    "    \"\"\"Check current memory usage\"\"\"\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"Memory usage: {mem_info.rss / 1e6:.2f} MB\")\n",
    "    return mem_info.rss / 1e6\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory by garbage collection\"\"\"\n",
    "    gc.collect()\n",
    "    if IN_COLAB:\n",
    "        tf.keras.backend.clear_session()\n",
    "    print(\"Memory cleared\")\n",
    "\n",
    "def monitor_memory(func):\n",
    "    \"\"\"Decorator to monitor memory usage of functions\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_mem = check_memory_usage()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_mem = check_memory_usage()\n",
    "        print(f\"Memory change: {end_mem - start_mem:.2f} MB\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "print(\"Memory management utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Import neuroimaging libraries\n",
    "import nibabel as nib\n",
    "from nilearn import plotting, image, datasets\n",
    "try:\n",
    "    import mne\n",
    "    MNE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MNE_AVAILABLE = False\n",
    "    print(\"MNE not available for MEG data processing\")\n",
    "\n",
    "# Import visualization libraries\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configure warnings and display\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to project directory and import project modules\n",
    "sys.path.append(project_path)\n",
    "os.chdir(project_path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Import project modules\n",
    "try:\n",
    "    from config import default_config\n",
    "    from utils.file_utils import list_files, load_json, save_json\n",
    "    from utils.data_utils import normalize_data, resize_data\n",
    "    from data_processing.data_loader import create_data_generator\n",
    "    from data_processing.fmri_preprocessing import preprocess_fmri\n",
    "    from visualization.interactive_plots import InteractivePlotter\n",
    "    from visualization.result_plots import ResultPlotter\n",
    "    print(\"Project modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: Could not import some project modules: {e}\")\n",
    "    print(\"Using minimal configuration for exploration\")\n",
    "    \n",
    "    # Create minimal configuration for testing\n",
    "    class MinimalConfig:\n",
    "        def __init__(self):\n",
    "            self.data = type('DataConfig', (), {\n",
    "                'data_root': './data',\n",
    "                'fmri_data_dir': './data/fmri',\n",
    "                'meg_data_dir': './data/meg',\n",
    "                'fmri_shape': (96, 96, 96, 4),\n",
    "                'meg_shape': (306, 100, 1000)\n",
    "            })()\n",
    "            self.visualization = type('VisualizationConfig', (), {\n",
    "                'output_dir': './visualizations'\n",
    "            })()\n",
    "    \n",
    "    default_config = MinimalConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Configuration for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration cell for easy parameter adjustment\n",
    "EXPLORATION_CONFIG = {\n",
    "    # Data paths\n",
    "    'data_root': default_config.data.data_root,\n",
    "    'fmri_dir': default_config.data.fmri_data_dir,\n",
    "    'meg_dir': default_config.data.meg_data_dir,\n",
    "    \n",
    "    # Exploration parameters\n",
    "    'max_subjects_to_load': 10,  # Limit for memory management\n",
    "    'sample_voxels': 10000,  # Number of voxels to sample for statistics\n",
    "    'visualize_slices': True,\n",
    "    'create_interactive_plots': True,\n",
    "    \n",
    "    # Visualization parameters\n",
    "    'figure_dpi': 150,\n",
    "    'figure_size': (12, 8),\n",
    "    'colormap': 'viridis',\n",
    "    \n",
    "    # Memory management\n",
    "    'clear_memory_after_each_subject': True,\n",
    "    'use_memory_mapping': True\n",
    "}\n",
    "\n",
    "# Update matplotlib parameters\n",
    "plt.rcParams['figure.dpi'] = EXPLORATION_CONFIG['figure_dpi']\n",
    "plt.rcParams['figure.figsize'] = EXPLORATION_CONFIG['figure_size']\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(EXPLORATION_CONFIG['data_root'], exist_ok=True)\n",
    "os.makedirs(default_config.visualization.output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Exploration configuration set:\")\n",
    "for key, value in EXPLORATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. fMRI Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available fMRI files with progress tracking\n",
    "print(\"Scanning for fMRI files...\")\n",
    "fmri_files = list_files(EXPLORATION_CONFIG['fmri_dir'], '.nii.gz')\n",
    "\n",
    "if not fmri_files:\n",
    "    print(\"No fMRI files found. Creating sample data for demonstration.\")\n",
    "    # Create sample data directory and files\n",
    "    os.makedirs(EXPLORATION_CONFIG['fmri_dir'], exist_ok=True)\n",
    "    \n",
    "    # Create a dummy fMRI file for demonstration\n",
    "    sample_shape = default_config.data.fmri_shape\n",
    "    sample_data = np.random.randn(*sample_shape)\n",
    "    sample_img = nib.Nifti1Image(sample_data, affine=np.eye(4))\n",
    "    \n",
    "    sample_path = os.path.join(EXPLORATION_CONFIG['fmri_dir'], 'sample_fmri.nii.gz')\n",
    "    nib.save(sample_img, sample_path)\n",
    "    fmri_files = [sample_path]\n",
    "    print(f\"Created sample fMRI file: {sample_path}\")\n",
    "\n",
    "print(f\"Found {len(fmri_files)} fMRI files\")\n",
    "if len(fmri_files) > 0:\n",
    "    print(f\"Example file: {fmri_files[0]}\")\n",
    "    \n",
    "    # Limit files for memory management\n",
    "    if len(fmri_files) > EXPLORATION_CONFIG['max_subjects_to_load']:\n",
    "        fmri_files = fmri_files[:EXPLORATION_CONFIG['max_subjects_to_load']]\n",
    "        print(f\"Limited to {len(fmri_files)} files for memory management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine fMRI data with memory management\n",
    "@monitor_memory\n",
    "def load_fmri_data(file_path, use_memory_mapping=True):\n",
    "    \"\"\"Load fMRI data with memory management options\"\"\"\n",
    "    try:\n",
    "        if use_memory_mapping:\n",
    "            # Use memory mapping for large files\n",
    "            img = nib.load(file_path, mmap='r+')\n",
    "        else:\n",
    "            img = nib.load(file_path)\n",
    "        \n",
    "        data = img.get_fdata()\n",
    "        return img, data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load first fMRI file for detailed analysis\n",
    "if fmri_files:\n",
    "    print(f\"\\nLoading fMRI data from: {fmri_files[0]}\")\n",
    "    fmri_img, fmri_data = load_fmri_data(\n",
    "        fmri_files[0], \n",
    "        use_memory_mapping=EXPLORATION_CONFIG['use_memory_mapping']\n",
    "    )\n",
    "    \n",
    "    if fmri_data is not None:\n",
    "        print(f\"fMRI data shape: {fmri_data.shape}\")\n",
    "        print(f\"Data type: {fmri_data.dtype}\")\n",
    "        print(f\"Data range: [{fmri_data.min():.4f}, {fmri_data.max():.4f}]\")\n",
    "        print(f\"Affine matrix shape: {fmri_img.affine.shape}\")\n",
    "        print(f\"Voxel size: {fmri_img.header.get_zooms()}\")\n",
    "        \n",
    "        # Calculate memory usage\n",
    "        data_size_mb = fmri_data.nbytes / 1e6\n",
    "        print(f\"Data size: {data_size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"No fMRI files available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. fMRI Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fMRI slices with interactive controls\n",
    "if fmri_files and EXPLORATION_CONFIG['visualize_slices']:\n",
    "    def plot_fmri_slices(data, slice_indices=None):\n",
    "        \"\"\"Plot fMRI slices in three dimensions\"\"\"\n",
    "        if slice_indices is None:\n",
    "            # Use middle slices\n",
    "            slice_indices = [\n",
    "                data.shape[0] // 2,  # Sagittal\n",
    "                data.shape[1] // 2,  # Coronal\n",
    "                data.shape[2] // 2   # Axial\n",
    "            ]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Handle 4D data (take first time point)\n",
    "        if len(data.shape) == 4:\n",
    "            data_3d = data[..., 0]\n",
    "        else:\n",
    "            data_3d = data\n",
    "        \n",
    "        # Sagittal slice\n",
    "        axes[0].imshow(data_3d[slice_indices[0], :, :], cmap=EXPLORATION_CONFIG['colormap'], origin='lower')\n",
    "        axes[0].set_title(f'Sagittal slice {slice_indices[0]}')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Coronal slice\n",
    "        axes[1].imshow(data_3d[:, slice_indices[1], :], cmap=EXPLORATION_CONFIG['colormap'], origin='lower')\n",
    "        axes[1].set_title(f'Coronal slice {slice_indices[1]}')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Axial slice\n",
    "        axes[2].imshow(data_3d[:, :, slice_indices[2]], cmap=EXPLORATION_CONFIG['colormap'], origin='lower')\n",
    "        axes[2].set_title(f'Axial slice {slice_indices[2]}')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot slices\n",
    "    plot_fmri_slices(fmri_data)\n",
    "    \n",
    "    # Interactive slice viewer\n",
    "    if EXPLORATION_CONFIG['create_interactive_plots']:\n",
    "        def interactive_slice_viewer(sagittal_idx, coronal_idx, axial_idx):\n",
    "            plot_fmri_slices(fmri_data, [sagittal_idx, coronal_idx, axial_idx])\n",
    "        \n",
    "        # Create interactive widgets\n",
    "        sagittal_slider = widgets.IntSlider(\n",
    "            min=0, max=fmri_data.shape[0]-1, \n",
    "            value=fmri_data.shape[0]//2, \n",
    "            description='Sagittal:'\n",
    "        )\n",
    "        coronal_slider = widgets.IntSlider(\n",
    "            min=0, max=fmri_data.shape[1]-1, \n",
    "            value=fmri_data.shape[1]//2, \n",
    "            description='Coronal:'\n",
    "        )\n",
    "        axial_slider = widgets.IntSlider(\n",
    "            min=0, max=fmri_data.shape[2]-1, \n",
    "            value=fmri_data.shape[2]//2, \n",
    "            description='Axial:'\n",
    "        )\n",
    "        \n",
    "        # Create interactive plot\n",
    "        widgets.interactive(\n",
    "            interactive_slice_viewer, \n",
    "            sagittal_idx=sagittal_slider,\n",
    "            coronal_idx=coronal_slider,\n",
    "            axial_idx=axial_slider\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nilearn for advanced visualization\n",
    "if fmri_files:\n",
    "    try:\n",
    "        print(\"Creating advanced nilearn visualizations...\")\n",
    "        \n",
    "        # Plot anatomical image with statistical map overlay\n",
    "        display = plotting.plot_anat(fmri_img, title=\"fMRI Anatomical View\", cut_coords=8)\n",
    "        plotting.show()\n",
    "        \n",
    "        # Create glass brain visualization\n",
    "        if len(fmri_data.shape) == 4:\n",
    "            # Create statistical map from first time point\n",
    "            stat_map = image.new_img_like(fmri_img, fmri_data[..., 0])\n",
    "        else:\n",
    "            stat_map = fmri_img\n",
    "        \n",
    "        plotting.plot_glass_brain(\n",
    "            stat_map, \n",
    "            title='Glass Brain View',\n",
    "            display_mode='ortho',\n",
    "            colorbar=True\n",
    "        )\n",
    "        plotting.show()\n",
    "        \n",
    "        # Save visualizations\n",
    "        output_dir = default_config.visualization.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        anat_path = os.path.join(output_dir, 'fmri_anatomical.png')\n",
    "        display.savefig(anat_path)\n",
    "        print(f\"Saved anatomical view to {anat_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in nilearn visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. fMRI Data Statistics and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive fMRI statistics\n",
    "if fmri_files:\n",
    "    print(\"\\n=== fMRI DATA STATISTICS ===\")\n",
    "    \n",
    "    # Handle 4D data\n",
    "    if len(fmri_data.shape) == 4:\n",
    "        print(f\"4D data detected with {fmri_data.shape[3]} time points\")\n",
    "        # Analyze first time point for basic statistics\n",
    "        data_3d = fmri_data[..., 0]\n",
    "        time_series_data = fmri_data\n",
    "    else:\n",
    "        data_3d = fmri_data\n",
    "        time_series_data = None\n",
    "    \n",
    "    # Flatten data for statistics\n",
    "    data_flat = data_3d.flatten()\n",
    "    \n",
    "    # Remove zeros (background)\n",
    "    data_nonzero = data_flat[data_flat != 0]\n",
    "    \n",
    "    print(f\"Total voxels: {len(data_flat):,}\")\n",
    "    print(f\"Non-zero voxels: {len(data_nonzero):,} ({len(data_nonzero)/len(data_flat)*100:.2f}%)\")\n",
    "    print(f\"Mean intensity: {data_nonzero.mean():.4f} ¬± {data_nonzero.std():.4f}\")\n",
    "    print(f\"Min intensity: {data_nonzero.min():.4f}\")\n",
    "    print(f\"Max intensity: {data_nonzero.max():.4f}\")\n",
    "    print(f\"Median: {np.median(data_nonzero):.4f}\")\n",
    "    print(f\"25th percentile: {np.percentile(data_nonzero, 25):.4f}\")\n",
    "    print(f\"75th percentile: {np.percentile(data_nonzero, 75):.4f}\")\n",
    "    print(f\"Skewness: {pd.Series(data_nonzero).skew():.4f}\")\n",
    "    print(f\"Kurtosis: {pd.Series(data_nonzero).kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of voxel intensities\n",
    "if fmri_files:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Main histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(data_nonzero, bins=100, alpha=0.7, density=True, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of Voxel Intensities')\n",
    "    plt.xlabel('Intensity')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log-scale histogram for better visualization of tail\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(data_nonzero, bins=100, alpha=0.7, density=True, color='lightcoral', edgecolor='black')\n",
    "    plt.title('Distribution of Voxel Intensities (Log Scale)')\n",
    "    plt.xlabel('Intensity')\n",
    "    plt.ylabel('Density (log scale)')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save histogram\n",
    "    hist_path = os.path.join(default_config.visualization.output_dir, 'fmri_intensity_histogram.png')\n",
    "    plt.savefig(hist_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "    print(f\"Saved histogram to {hist_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "if fmri_files:\n",
    "    print(\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_count = np.isnan(data_3d).sum()\n",
    "    print(f\"Number of NaN values: {nan_count:,}\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    inf_count = np.isinf(data_3d).sum()\n",
    "    print(f\"Number of infinite values: {inf_count:,}\")\n",
    "    \n",
    "    # Check for outliers (values beyond 3 standard deviations)\n",
    "    mean_val = data_nonzero.mean()\n",
    "    std_val = data_nonzero.std()\n",
    "    outliers = data_nonzero[(data_nonzero < mean_val - 3*std_val) | (data_nonzero > mean_val + 3*std_val)]\n",
    "    print(f\"Number of outliers (¬±3œÉ): {len(outliers):,} ({len(outliers)/len(data_nonzero)*100:.2f}%)\")\n",
    "    \n",
    "    # Check for potential artifacts\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"Outlier range: [{outliers.min():.4f}, {outliers.max():.4f}]\")\n",
    "    \n",
    "    # Check data distribution quality\n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(\"WARNING: Data contains NaN or infinite values!\")\n",
    "    else:\n",
    "        print(\"Data quality check passed: No NaN or infinite values found.\")\n",
    "    \n",
    "    # Time series analysis if 4D data\n",
    "    if time_series_data is not None:\n",
    "        print(f\"\\n=== TIME SERIES ANALYSIS ===\")\n",
    "        print(f\"Number of time points: {time_series_data.shape[3]}\")\n",
    "        \n",
    "        # Calculate temporal signal-to-noise ratio (tSNR)\n",
    "        temporal_mean = np.mean(time_series_data, axis=3)\n",
    "        temporal_std = np.std(time_series_data, axis=3)\n",
    "        tsnr = temporal_mean / (temporal_std + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "        \n",
    "        # Calculate tSNR for brain voxels only\n",
    "        brain_mask = temporal_mean > temporal_mean.mean()  # Simple threshold for brain mask\n",
    "        brain_tsnr = tsnr[brain_mask]\n",
    "        \n",
    "        print(f\"Mean tSNR: {brain_tsnr.mean():.2f} ¬± {brain_tsnr.std():.2f}\")\n",
    "        print(f\"tSNR range: [{brain_tsnr.min():.2f}, {brain_tsnr.max():.2f}]\")\n",
    "        \n",
    "        # Plot tSNR map\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(tsnr[:, :, tsnr.shape[2]//2], cmap=EXPLORATION_CONFIG['colormap'], origin='lower')\n",
    "        plt.title(f'tSNR Map (Slice {tsnr.shape[2]//2})')\n",
    "        plt.colorbar(label='tSNR')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save tSNR map\n",
    "        tsnr_path = os.path.join(default_config.visualization.output_dir, 'fmri_tsnr_map.png')\n",
    "        plt.savefig(tsnr_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved tSNR map to {tsnr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MEG Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and explore MEG files\n",
    "print(\"\\nScanning for MEG files...\")\n",
    "meg_files = list_files(EXPLORATION_CONFIG['meg_dir'], '.fif')\n",
    "\n",
    "if not meg_files:\n",
    "    print(\"No MEG files found. Creating sample data for demonstration.\")\n",
    "    # Create sample MEG directory and files\n",
    "    os.makedirs(EXPLORATION_CONFIG['meg_dir'], exist_ok=True)\n",
    "    print(\"MEG data exploration requires actual .fif files for detailed analysis.\")\n",
    "else:\n",
    "    print(f\"Found {len(meg_files)} MEG files\")\n",
    "    print(f\"Example file: {meg_files[0]}\")\n",
    "    \n",
    "    # Limit files for memory management\n",
    "    if len(meg_files) > EXPLORATION_CONFIG['max_subjects_to_load']:\n",
    "        meg_files = meg_files[:EXPLORATION_CONFIG['max_subjects_to_load']]\n",
    "        print(f\"Limited to {len(meg_files)} files for memory management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine MEG data if available\n",
    "if meg_files and MNE_AVAILABLE:\n",
    "    try:\n",
    "        print(f\"\\nLoading MEG data from: {meg_files[0]}\")\n",
    "        \n",
    "        # Load MEG data with progress tracking\n",
    "        with tqdm(total=1, desc=\"Loading MEG data\") as pbar:\n",
    "            raw = mne.io.read_raw_fif(meg_files[0], preload=True)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Extract basic information\n",
    "        meg_data = raw.get_data()\n",
    "        print(f\"MEG data shape: {meg_data.shape}\")\n",
    "        print(f\"Sampling frequency: {raw.info['sfreq']} Hz\")\n",
    "        print(f\"Duration: {raw.times[-1]:.2f} seconds\")\n",
    "        print(f\"Number of channels: {len(raw.ch_names)}\")\n",
    "        \n",
    "        # Get channel types\n",
    "        channel_types = {}\n",
    "        for ch in raw.ch_names:\n",
    "            ch_type = mne.channel_type(raw.info, ch)\n",
    "            channel_types[ch_type] = channel_types.get(ch_type, 0) + 1\n",
    "        \n",
    "        print(\"\\nChannel types:\")\n",
    "        for ch_type, count in channel_types.items():\n",
    "            print(f\"  {ch_type}: {count}\")\n",
    "        \n",
    "        # Calculate memory usage\n",
    "        data_size_mb = meg_data.nbytes / 1e6\n",
    "        print(f\"Data size: {data_size_mb:.2f} MB\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nMEG Signal Statistics:\")\n",
    "        print(f\"Mean: {meg_data.mean():.4e} ¬± {meg_data.std():.4e}\")\n",
    "        print(f\"Range: [{meg_data.min():.4e}, {meg_data.max():.4e}]\")\n",
    "        \n",
    "        # Visualize MEG data\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot first few channels\n",
    "        n_channels_to_plot = min(10, len(raw.ch_names))\n",
    "        time_points = raw.times[:1000]  # First 1000 time points\n",
    "        \n",
    "        for i in range(n_channels_to_plot):\n",
    "            plt.subplot(n_channels_to_plot, 1, i+1)\n",
    "            plt.plot(time_points, meg_data[i, :len(time_points)])\n",
    "            plt.title(f\"Channel: {raw.ch_names[i]}\")\n",
    "            plt.ylabel('Amplitude')\n",
    "            if i == n_channels_to_plot - 1:\n",
    "                plt.xlabel('Time (s)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save MEG visualization\n",
    "        meg_plot_path = os.path.join(default_config.visualization.output_dir, 'meg_signals.png')\n",
    "        plt.savefig(meg_plot_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved MEG signals plot to {meg_plot_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading MEG data: {e}\")\n",
    "else:\n",
    "    if not MNE_AVAILABLE:\n",
    "        print(\"MNE package not available for MEG data exploration\")\n",
    "    else:\n",
    "        print(\"No MEG files available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Analysis and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze metadata if available\n",
    "metadata_path = os.path.join(EXPLORATION_CONFIG['data_root'], 'metadata.csv')\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    print(f\"Loading metadata from: {metadata_path}\")\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    print(f\"Metadata shape: {metadata.shape}\")\n",
    "    \n",
    "    print(\"\\nColumns:\")\n",
    "    for col in metadata.columns:\n",
    "        print(f\"  {col}\")\n",
    "    \n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(metadata.head())\n",
    "    \n",
    "    # Check class distribution\n",
    "    if 'diagnosis' in metadata.columns:\n",
    "        print(\"\\nDiagnosis distribution:\")\n",
    "        diagnosis_counts = metadata['diagnosis'].value_counts()\n",
    "        print(diagnosis_counts)\n",
    "        \n",
    "        # Plot diagnosis distribution\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        diagnosis_counts.plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "        plt.title('Diagnosis Distribution')\n",
    "        plt.xlabel('Diagnosis')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save diagnosis distribution plot\n",
    "        diagnosis_path = os.path.join(default_config.visualization.output_dir, 'diagnosis_distribution.png')\n",
    "        plt.savefig(diagnosis_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved diagnosis distribution to {diagnosis_path}\")\n",
    "    \n",
    "    # Plot age distribution by diagnosis if available\n",
    "    if 'age' in metadata.columns and 'diagnosis' in metadata.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='diagnosis', y='age', data=metadata)\n",
    "        plt.title('Age Distribution by Diagnosis')\n",
    "        plt.xlabel('Diagnosis')\n",
    "        plt.ylabel('Age')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save age distribution plot\n",
    "        age_path = os.path.join(default_config.visualization.output_dir, 'age_distribution.png')\n",
    "        plt.savefig(age_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved age distribution to {age_path}\")\n",
    "    \n",
    "    # Gender distribution if available\n",
    "    if 'gender' in metadata.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        gender_counts = metadata['gender'].value_counts()\n",
    "        gender_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "        plt.title('Gender Distribution')\n",
    "        plt.ylabel('')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save gender distribution plot\n",
    "        gender_path = os.path.join(default_config.visualization.output_dir, 'gender_distribution.png')\n",
    "        plt.savefig(gender_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved gender distribution to {gender_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No metadata file found. Creating sample metadata for demonstration.\")\n",
    "    \n",
    "    # Create sample metadata\n",
    "    n_subjects = max(len(fmri_files), len(meg_files), 20)  # At least 20 subjects\n",
    "    sample_metadata = pd.DataFrame({\n",
    "        'subject_id': [f\"sub-{i:03d}\" for i in range(n_subjects)],\n",
    "        'age': np.random.randint(18, 65, n_subjects),\n",
    "        'gender': np.random.choice(['M', 'F'], n_subjects),\n",
    "        'diagnosis': np.random.choice(['control', 'schizophrenia'], n_subjects, p=[0.6, 0.4]),\n",
    "        'site': np.random.choice(['site1', 'site2', 'site3'], n_subjects)\n",
    "    })\n",
    "    \n",
    "    # Save sample metadata\n",
    "    os.makedirs(EXPLORATION_CONFIG['data_root'], exist_ok=True)\n",
    "    sample_metadata.to_csv(metadata_path, index=False)\n",
    "    print(f\"Created sample metadata with {n_subjects} subjects: {metadata_path}\")\n",
    "    \n",
    "    display(sample_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive 3D visualization of fMRI data\n",
    "if fmri_files and EXPLORATION_CONFIG['create_interactive_plots']:\n",
    "    try:\n",
    "        print(\"Creating interactive 3D visualization...\")\n",
    "        \n",
    "        # Handle 4D data\n",
    "        if len(fmri_data.shape) == 4:\n",
    "            data_3d = fmri_data[..., 0]\n",
    "        else:\n",
    "            data_3d = fmri_data\n",
    "        \n",
    "        # Create interactive volume visualization using plotly\n",
    "        # Sample the data for better performance\n",
    "        sample_step = max(1, data_3d.shape[0] // 50)  # Limit to ~50 slices in each dimension\n",
    "        sampled_data = data_3d[::sample_step, ::sample_step, ::sample_step]\n",
    "        \n",
    "        # Create 3D volume plot\n",
    "        fig = go.Figure(data=go.Volume(\n",
    "            x=np.arange(sampled_data.shape[0]),\n",
    "            y=np.arange(sampled_data.shape[1]),\n",
    "            z=np.arange(sampled_data.shape[2]),\n",
    "            value=sampled_data.flatten(),\n",
    "            isomin=sampled_data.min(),\n",
    "            isomax=sampled_data.max(),\n",
    "            opacity=0.1,\n",
    "            surface_count=10,\n",
    "            colorscale='Viridis'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Interactive 3D fMRI Volume',\n",
    "            scene=dict(\n",
    "                xaxis_title='X',\n",
    "                yaxis_title='Y',\n",
    "                zaxis_title='Z'\n",
    "            ),\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Save interactive plot\n",
    "        interactive_path = os.path.join(default_config.visualization.output_dir, 'interactive_fmri.html')\n",
    "        fig.write_html(interactive_path)\n",
    "        print(f\"Saved interactive visualization to {interactive_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating interactive visualization: {e}\")\n",
    "        print(\"Interactive visualization may not work in all environments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive dashboard for data exploration\n",
    "if EXPLORATION_CONFIG['create_interactive_plots']:\n",
    "    try:\n",
    "        print(\"Creating interactive dashboard...\")\n",
    "        \n",
    "        # Create dashboard tabs\n",
    "        tab = widgets.Tab()\n",
    "        \n",
    "        # Tab 1: Data Overview\n",
    "        overview_tab = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Data Overview</h3>\"),\n",
    "            widgets.HTML(f\"<p><b>fMRI files:</b> {len(fmri_files)}</p>\"),\n",
    "            widgets.HTML(f\"<p><b>MEG files:</b> {len(meg_files)}</p>\"),\n",
    "            widgets.HTML(f\"<p><b>Data root:</b> {EXPLORATION_CONFIG['data_root']}</p>\")\n",
    "        ])\n",
    "        \n",
    "        # Tab 2: Configuration\n",
    "        config_tab = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Configuration</h3>\"),\n",
    "            widgets.HTML(f\"<p><b>Max subjects:</b> {EXPLORATION_CONFIG['max_subjects_to_load']}</p>\"),\n",
    "            widgets.HTML(f\"<p><b>Sample voxels:</b> {EXPLORATION_CONFIG['sample_voxels']}</p>\"),\n",
    "            widgets.HTML(f\"<p><b>Memory mapping:</b> {EXPLORATION_CONFIG['use_memory_mapping']}</p>\")\n",
    "        ])\n",
    "        \n",
    "        # Tab 3: Memory Usage\n",
    "        memory_tab = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Memory Usage</h3>\"),\n",
    "            widgets.Button(description=\"Check Memory\", button_style='info')\n",
    "        ])\n",
    "        \n",
    "        # Set up tabs\n",
    "        tab.children = [overview_tab, config_tab, memory_tab]\n",
    "        tab.set_title(0, 'Overview')\n",
    "        tab.set_title(1, 'Configuration')\n",
    "        tab.set_title(2, 'Memory')\n",
    "        \n",
    "        display(tab)\n",
    "        \n",
    "        # Memory check button functionality\n",
    "        def on_memory_button_clicked(b):\n",
    "            clear_memory()\n",
    "            check_memory_usage()\n",
    "        \n",
    "        memory_tab.children[1].on_click(on_memory_button_clicked)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate preprocessing pipeline steps\n",
    "if fmri_files:\n",
    "    print(\"\\n=== PREPROCESSING PIPELINE DEMONSTRATION ===\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Original data\n",
    "        print(\"Step 1: Original data\")\n",
    "        original_data = fmri_data\n",
    "        if len(original_data.shape) == 4:\n",
    "            original_data = original_data[..., 0]\n",
    "        \n",
    "        # Step 2: Normalization\n",
    "        print(\"Step 2: Normalization\")\n",
    "        normalized_data = normalize_data(original_data, method='standard')\n",
    "        \n",
    "        # Step 3: Smoothing (if available)\n",
    "        print(\"Step 3: Smoothing\")\n",
    "        try:\n",
    "            from nilearn import image\n",
    "            smoothed_img = image.smooth_img(fmri_img, fwhm=6)\n",
    "            smoothed_data = smoothed_img.get_fdata()\n",
    "            if len(smoothed_data.shape) == 4:\n",
    "                smoothed_data = smoothed_data[..., 0]\n",
    "        except:\n",
    "            print(\"Skipping smoothing step\")\n",
    "            smoothed_data = normalized_data\n",
    "        \n",
    "        # Step 4: Resampling (if needed)\n",
    "        print(\"Step 4: Resampling to standard space\")\n",
    "        try:\n",
    "            target_shape = (64, 64, 64)\n",
    "            resampled_data = resize_data(normalized_data, target_shape)\n",
    "        except:\n",
    "            print(\"Skipping resampling step\")\n",
    "            resampled_data = normalized_data\n",
    "        \n",
    "        # Visualize preprocessing steps\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Original data\n",
    "        mid_slice = original_data.shape[2] // 2\n",
    "        axes[0, 0].imshow(original_data[:, :, mid_slice], cmap='gray', origin='lower')\n",
    "        axes[0, 0].set_title('Original Data')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Normalized data\n",
    "        axes[0, 1].imshow(normalized_data[:, :, mid_slice], cmap='gray', origin='lower')\n",
    "        axes[0, 1].set_title('Normalized Data')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Smoothed data\n",
    "        axes[1, 0].imshow(smoothed_data[:, :, mid_slice], cmap='gray', origin='lower')\n",
    "        axes[1, 0].set_title('Smoothed Data')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Resampled data\n",
    "        if 'resampled_data' in locals():\n",
    "            resampled_slice = resampled_data.shape[2] // 2\n",
    "            axes[1, 1].imshow(resampled_data[:, :, resampled_slice], cmap='gray', origin='lower')\n",
    "            axes[1, 1].set_title('Resampled Data')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Resampling\\nSkipped', \n",
    "                           ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_title('Resampled Data')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save preprocessing visualization\n",
    "        prep_path = os.path.join(default_config.visualization.output_dir, 'preprocessing_pipeline.png')\n",
    "        plt.savefig(prep_path, dpi=EXPLORATION_CONFIG['figure_dpi'], bbox_inches='tight')\n",
    "        print(f\"Saved preprocessing pipeline to {prep_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing demonstration: {e}\")\n",
    "else:\n",
    "    print(\"No fMRI data available for preprocessing demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA EXPLORATION SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÅ Data Overview:\")\n",
    "print(f\"  - fMRI files found: {len(fmri_files)}\")\n",
    "print(f\"  - MEG files found: {len(meg_files)}\")\n",
    "print(f\"  - Data root directory: {EXPLORATION_CONFIG['data_root']}\")\n",
    "\n",
    "if fmri_files:\n",
    "    print(f\"\\nüß† fMRI Data Analysis:\")\n",
    "    print(f\"  - Data shape: {fmri_data.shape}\")\n",
    "    print(f\"  - Data type: {fmri_data.dtype}\")\n",
    "    print(f\"  - Non-zero voxels: {len(data_nonzero):,} ({len(data_nonzero)/len(data_flat)*100:.2f}%)\")\n",
    "    print(f\"  - Mean intensity: {data_nonzero.mean():.4f} ¬± {data_nonzero.std():.4f}\")\n",
    "    print(f\"  - Data quality: {'‚úì PASS' if nan_count == 0 and inf_count == 0 else '‚úó FAIL'}\")\n",
    "\n",
    "if meg_files and MNE_AVAILABLE:\n",
    "    print(f\"\\nüîä MEG Data Analysis:\")\n",
    "    print(f\"  - Files available: {len(meg_files)}\")\n",
    "    print(f\"  - Channel types: {list(channel_types.keys()) if 'channel_types' in locals() else 'N/A'}\")\n",
    "\n",
    "if 'metadata' in locals():\n",
    "    print(f\"\\nüë• Group Analysis:\")\n",
    "    print(f\"  - Total subjects: {len(metadata)}\")\n",
    "    if 'diagnosis' in metadata.columns:\n",
    "        print(f\"  - Diagnosis distribution: {dict(metadata['diagnosis'].value_counts())}\")\n",
    "    if 'age' in metadata.columns:\n",
    "        print(f\"  - Age range: {metadata['age'].min()} - {metadata['age'].max()} years\")\n",
    "\n",
    "print(f\"\\nüîß Configuration:\")\n",
    "print(f\"  - Max subjects loaded: {EXPLORATION_CONFIG['max_subjects_to_load']}\")\n",
    "print(f\"  - Memory mapping enabled: {EXPLORATION_CONFIG['use_memory_mapping']}\")\n",
    "print(f\"  - Interactive plots: {EXPLORATION_CONFIG['create_interactive_plots']}\")\n",
    "\n",
    "print(f\"\\nüìä Generated Visualizations:\")\n",
    "output_dir = default_config.visualization.output_dir\n",
    "if os.path.exists(output_dir):\n",
    "    viz_files = [f for f in os.listdir(output_dir) if f.endswith(('.png', '.html'))]\n",
    "    for viz_file in viz_files:\n",
    "        print(f\"  - {viz_file}\")\n",
    "\n",
    "print(f\"\\nüíæ Output Directory: {output_dir}\")\n",
    "print(f\"\\nüöÄ Ready for model training!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export exploration results to Google Drive\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        # Create exploration summary file\n",
    "        exploration_summary = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'data_summary': {\n",
    "                'fmri_files_count': len(fmri_files),\n",
    "                'meg_files_count': len(meg_files),\n",
    "                'data_root': EXPLORATION_CONFIG['data_root']\n",
    "            },\n",
    "            'configuration': EXPLORATION_CONFIG,\n",
    "            'visualizations_generated': viz_files if 'viz_files' in locals() else []\n",
    "        }\n",
    "        \n",
    "        if fmri_files:\n",
    "            exploration_summary['fmri_stats'] = {\n",
    "                'shape': list(fmri_data.shape),\n",
    "                'dtype': str(fmri_data.dtype),\n",
    "                'nonzero_voxels': int(len(data_nonzero)),\n",
    "                'mean_intensity': float(data_nonzero.mean()),\n",
    "                'std_intensity': float(data_nonzero.std()),\n",
    "                'data_quality': 'PASS' if nan_count == 0 and inf_count == 0 else 'FAIL'\n",
    "            }\n",
    "        \n",
    "        # Save summary to Google Drive\n",
    "        summary_path = os.path.join(project_path, 'exploration_summary.json')\n",
    "        with open(summary_path, 'w') as f:\n",
    "            json.dump(exploration_summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nüìã Exploration summary saved to Google Drive: {summary_path}\")\n",
    "        \n",
    "        # Copy visualizations to Google Drive\n",
    "        import shutil\n",
    "        drive_viz_dir = os.path.join(project_path, 'exploration_visualizations')\n",
    "        if os.path.exists(output_dir):\n",
    "            shutil.copytree(output_dir, drive_viz_dir, dirs_exist_ok=True)\n",
    "            print(f\"üìä Visualizations copied to Google Drive: {drive_viz_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting to Google Drive: {e}\")\n",
    "else:\n",
    "    print(\"\\nüìã Exploration complete. Results saved locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up memory before ending\n",
    "print(\"\\nüßπ Cleaning up memory...\")\n",
    "clear_memory()\n",
    "check_memory_usage()\n",
    "print(\"\\n‚úÖ Data exploration notebook completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run the model_training.ipynb notebook to train the SSPNet model\")\n",
    "print(\"2. Use the results_analysis.ipynb notebook to evaluate and visualize results\")\n",
    "print(\"3. Check the generated visualizations in the output directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}